# CellMind â€“ **ë¶„ì‚° ë¯¸ë‹ˆ-GPT** í”„ë¡œì íŠ¸ ê°€ì´ë“œ (2025-04-29 rev)

ë‹¹ì—°í•˜ê²Œë„ ì±—ì§€í”¼í‹°ì™€ ì»¤ì„œê°€ ë‹¤ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.   

**ì•„ì§ í…ŒìŠ¤íŠ¸ ëª» í•´ë´¤ì–´ìš”. ë‹¨ë§ê¸°ê°€ ì—†ì–´ì„œ....ã…ã…**   
**ì‹œê°„ ë‚  ë•Œ ë‹¨ê³„ë³„ë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  ìˆ˜ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.**   
**í† í¬ë‚˜ì´ì € ë¶€ë¶„ í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì • ì™„ë£Œ. ğŸ”¨**   

## 0. ëª©ì°¨

1. [ì‚¬ì „ ì¤€ë¹„](#prereq)
2. [ë°ì´í„°Â·í† í¬ë‚˜ì´ì € ì¤€ë¹„](#data)
3. [`shared/config.json`] ì„¤ì •ë²•
4. [ë©”ì¸ ë‹¨ë§ (Orchestrator)](#orch)
5. [ì›Œì»¤ ë‹¨ë§](#worker)
6. [ì¶”ë¡  / ì²´í¬í¬ì¸íŠ¸ ë™ê¸°í™”](#infer-sync)
7. [ê¸°íƒ€ íŒ](#tips)

---

<a name="prereq"></a>

## 1. ì‚¬ì „ ì¤€ë¹„

```bash
# 1) ì €ì¥ì†Œ í´ë¡ 
git clone {repos}
cd cellmind

# 2) ê°€ìƒí™˜ê²½
python -m venv venv
source venv/bin/activate        # Win: venv\Scripts\activate

# 3) ì˜ì¡´ì„±
pip install -r requirements.txt
```

> **ëª¨ë“  ë‹¨ë§(ë©”ì¸Â·ì›Œì»¤)ì—ì„œ ë™ì¼í•˜ê²Œ** ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

---

<a name="data"></a>

## 2. ë°ì´í„° & í† í¬ë‚˜ì´ì €

| ë‹¨ê³„     | íŒŒì¼/ë””ë ‰í„°ë¦¬                                                                                                                | ì„¤ëª…                                      |
|--------|------------------------------------------------------------------------------------------------------------------------|-----------------------------------------|
| â‘  ğŸ”¨   | `data/raw/*.txt`                                                                                                       | ì›ë³¸ ë¡œ ë°ì´í„°                                |
| â‘¡ ğŸ”¨   | **í† í¬ë‚˜ì´ì € í•™ìŠµ**<br>`python -m tokenizer`                                                                                  | â†’ `{path}/tokenizer.model`              |
| â‘¢ TODO | **JSONL ë³€í™˜**<br>ê° ì¤„ `{"text": "..."} `                                                                                 | â†’ `data/for-model-training/train.jsonl` |
| â‘£ TODO | í•™ìŠµ ì‹œ **`TextDataset`** ê°€ ì´ JSONLì„ ì½ì–´ ìë™ìœ¼ë¡œ `<\|start\|> â€¦ <\|endoftext\|>` í† í°ì„ ë¶™ì´ê³ , `collate_fn` ìœ¼ë¡œ ë°°ì¹˜ íŒ¨ë”©(-100 mask) ì²˜ë¦¬ |

### 2.1 ì˜ˆì œ. raw_data

```csv
Date,User,Message
2022-10-30 10:35:01,"ê°•XX","ì´íƒœì› ê°€ì„œ ë‹¤ì¹œ ë¶„ë“¤ ì—†ê² ì§€ ì—¬ê¸´????"
2022-10-30 10:35:32,"ê¹€YY","ì—†ì„ê±¸?"
2022-10-30 10:37:48,"ê°•XX","ì •ë§ í°ì¼ í„°ì¡Œë”ë¼"
2022-10-30 10:37:53,"ê°•XX","ì¡°ì‹¬ë“¤ í•˜ì"
```

### 2.2 ì˜ˆì œ. ì •ì œ.

```python
import pandas as pd
import random
import re


# timestamp ì¶”ì¶œ
def timestamp() -> list[str]:
    df = pd.read_csv("data/raw/group_chat_001.csv")
    df["timestamp"] = pd.to_datetime(df["Date"])
    df["timestamp"] = df["timestamp"].dt.strftime("%Y-%m-%dT%H:%M:%S")
    return sorted(random.choices(df["timestamp"].tolist(), k=50))


# ì´ë¦„ ì¶”ì¶œ
def nameonly() -> list[str]:
    df1 = pd.read_csv("data/raw/group_chat_001.csv")
    df2 = pd.read_csv("data/raw/group_chat_002.csv")
    df3 = pd.read_csv("data/raw/group_chat_003.csv")
    df = pd.concat([df1, df2, df3], ignore_index=True)

    return df["User"].unique().tolist()


# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
def preprocess_message(fullname: set[str], firstnames: list[str]) -> list[str]:
    # CSV íŒŒì¼ ë¡œë“œ ë° ë³‘í•©
    df1 = pd.read_csv("data/raw/group_chat_001.csv")
    df2 = pd.read_csv("data/raw/group_chat_002.csv")
    df3 = pd.read_csv("data/raw/group_chat_003.csv")
    df = pd.concat([df1, df2, df3], ignore_index=True)

    # ì›ë³¸ ë©”ì‹œì§€ ì†Œë¬¸ì ë³€í™˜
    messages = df["Message"].astype(str).str.lower().tolist()

    # ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼
    photo_pattern = re.compile(r'^ì‚¬ì§„(\s*\d+ì¥)?$')
    movie_pattern = re.compile(r'^ë™ì˜ìƒ$')
    url_pattern = re.compile(r'https?://\S+')
    emoji_pattern = re.compile(
        r"[\U0001F600-\U0001F64F"  # emoticons
        r"\U0001F300-\U0001F5FF"  # symbols & pictographs
        r"\U0001F680-\U0001F6FF"  # transport & map symbols
        r"\U0001F1E0-\U0001F1FF"  # flags
        r"\U0001F900-\U0001F9FF"  # Supplemental Symbols and Pictographs
        r"\U0001FA00-\U0001FA6F"  # Chess Symbols etc.
        r"\U0001FA70-\U0001FAFF"  # Symbols and Pictographs Extended-A
        r"\u2600-\u26FF\u2700-\u27BF]+", flags=re.UNICODE)
    # 5ê°œ ì´ìƒ ë°˜ë³µë˜ëŠ” ë¹„ê³µë°± ë¬¸ì ì¼ë°˜í™”
    repeat_pattern = re.compile(r'(\S)\1{4,}')
    newline_pattern = re.compile(r'\n+')
    ws_paren_pattern = re.compile(r'\(\s*\)')
    entire_names = list(fullname) + firstnames
    name_pattern = re.compile(r'|'.join(entire_names))

    processed = []
    for msg in messages:
        # ZWSP ì œê±°
        msg = msg.replace('\u200b', '')
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆ í•˜ë‚˜ë¡œ ì¶•ì†Œ
        msg = newline_pattern.sub('\n', msg)
        msg = msg.strip()

        # ì „ì²´ ë©”ì‹œì§€ê°€ ì‚¬ì§„/ë™ì˜ìƒ/ì´ëª¨í‹°ì½˜ì¸ ê²½ìš° ì¹˜í™˜
        if photo_pattern.match(msg):
            processed.append('<PHOTO>')
            continue
        if movie_pattern.match(msg):
            processed.append('<MOVIE>')
            continue
        if msg == 'ì´ëª¨í‹°ì½˜':
            processed.append('<EMOJI>')
            continue

        # URL, ì´ëª¨ì§€, ë°˜ë³µ ë¬¸ì, ë¶ˆí•„ìš” íŒ¨í„´ ì¹˜í™˜
        msg = url_pattern.sub('<URL>', msg)
        msg = emoji_pattern.sub('<EMOJI>', msg)
        msg = repeat_pattern.sub(lambda m: m.group(1) * 5, msg)
        msg = ws_paren_pattern.sub('', msg)
        msg = name_pattern.sub('<NAME>', msg)

        processed.append(msg)

    return processed


# ì¶”ì¶œí•œ ì´ë¦„ìœ¼ë¡œ ëŒ€í™” ë‚´ìš©ì— ìˆëŠ” ì´ë¦„ì„ <NAME> í† í°ìœ¼ë¡œ ë³€í™”ì‹œí‚´
names = nameonly()
fullname = set()
firstname_only = []
for name in names:
    processed_name = name.replace(" ", "")
    re_search = re.search("[ê°€-í£]{3}", processed_name)
    if re_search:
        fullname.add(re_search.group())
    else:
        # ê°€ì§€ê³  ê³„ì‹  ë°ì´í„°ì— ë§ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.
        pass
```

### 2.3 ì˜ˆì œ. í† í¬ë‚˜ì´ì € í•™ìŠµ ì‹¤í–‰.

```bash
python -m tokenizer --input data/for-tokenizer-training/textonly.txt --model-prefix minigpt --character-coverage 0.98 --model-type bpe --output-dir tokenizer
```

```bash
> ls -al tokenizer

total 1000tokenizer                                                                                                                                            â”€â•¯
drwxr-xr-x   8 needmoney  staff     256 Apr 29 13:37 .
drwxr-xr-x  20 needmoney  staff     640 Apr 29 13:46 ..
-rw-r--r--@  1 needmoney  staff    3524 Apr 29 13:36 __init__.py
-rw-r--r--   1 needmoney  staff      58 Apr 29 13:06 __main__.py
drwxr-xr-x   5 needmoney  staff     160 Apr 29 13:36 __pycache__
##### ìƒì„± ##### 
-rw-r--r--   1 needmoney  staff  373645 Apr 29 13:36 minigpt.model
-rw-r--r--   1 needmoney  staff  118815 Apr 29 13:36 minigpt.vocab
###############
-rw-r--r--@  1 needmoney  staff    3045 Apr 29 13:37 sentencepiece_tokenizer.py

```

---

## 3. `shared/config.json` ì˜ˆì‹œ

```jsonc
{
  "distributed": {
    "backend": "gloo",                   // CPU-only â†’ gloo, GPU â†’ nccl
    "init_method": "tcp://192.168.0.100:23456",
    "world_size": 3,                     // 1(ë©”ì¸) + 2(ì›Œì»¤)
    "worker_ips": [
      "192.168.0.101",
      "192.168.0.102"
    ],
    "usernames": {
      "192.168.0.101": "laptop_user",
      "192.168.0.102": "termux_user"
    }
  },

  "model": {
    "d_model":     512,
    "nhead":       8,
    "num_layers":  6,
    "dropout":     0.1,
    "checkpoint":  "checkpoints/latest.pt"   // ìµœì´ˆ í•™ìŠµ ì‹œ ë¹„ì›Œë‘¬ë„ ë¨
  },

  "tokenizer": {
    "model_path":  "tokenizer/tokenizer.model",
    "vocab_size":  8000
  },

  "training": {
    "batch_size":  32,
    "epochs":      3,
    "lr":          3e-4,
    "dataset": {
      "path":      "data/for-model-training/train.jsonl",
      "seq_len":   256
    }
  }
}
```

---

<a name="orch"></a>

## 4. ë©”ì¸ ë‹¨ë§ (Orchestrator)

### 4-1. SSH ì¤€ë¹„ (ìµœì´ˆ 1íšŒ)

```bash
ssh-keygen -t rsa -b 4096 -N ""      # í‚¤ ì—†ìœ¼ë©´ ìƒì„±
ssh-copy-id laptop_user@192.168.0.101
ssh-copy-id termux_user@192.168.0.102
```

### 4-2. í•™ìŠµ ì‹œì‘

```bash
python orchestrator/manager.py --mode train
```

* `manager.py` ê°€ ê° ì›Œì»¤ì— **í™˜ê²½ë³€ìˆ˜(MASTER_ADDR Â· RANK ë“±)** ë¥¼ í¬í•¨í•œ
  `python -m worker.processor --mode train` ëª…ë ¹ì„ SSHë¡œ ì „ì†¡ â†’ í•™ìŠµ ìë™ ì‹œì‘.

### 4-3. ì‹¤ì‹œê°„ ë¡œê·¸

ë©”ì¸ ë‹¨ë§ ì½˜ì†”ì— rank 0 ë¡œê·¸ê°€ ì¶œë ¥ë˜ê³ , ì›Œì»¤ ì½˜ì†”ì—ëŠ” ê°ì rank ë¡œê·¸ê°€ ëœ¹ë‹ˆë‹¤.

---

<a name="worker"></a>

## 5. ì›Œì»¤ ë‹¨ë§

| í•­ëª©                     | Linux laptop               | Android (ì˜ˆ: Termux)                       |
|------------------------|----------------------------|-------------------------------------------|
| ë ˆí¬ í´ë¡ Â·venvÂ·pip install | ë©”ì¸ê³¼ ë™ì¼                     | ```pkg install python git openssh``` í›„ ë™ì¼ |
| SSH ì„œë²„                 | ë³´í†µ ì´ë¯¸ `sshd` ì‹¤í–‰ ì¤‘          | ```sshd``` ì‹¤í–‰                             |
| **ì‹¤í–‰ í•„ìš” ì—†ìŒ**           | Orchestratorê°€ ì•Œì•„ì„œ í”„ë¡œì„¸ìŠ¤ë¥¼ ë„ì›€ | Orchestratorê°€ ì•Œì•„ì„œ í”„ë¡œì„¸ìŠ¤ë¥¼ ë„ì›€                |

---

<a name="infer-sync"></a>

## 6. ì¶”ë¡  & ì²´í¬í¬ì¸íŠ¸ ë™ê¸°í™”

| ëª¨ë“œ                 | ëª…ë ¹                                                                         |
|--------------------|----------------------------------------------------------------------------|
| **ì¶”ë¡ **             | `python orchestrator/manager.py --mode inference --prompt "ì•ˆë…• GPT!"`       |
| **íŒŒì¼ë¡œ ì¶”ë¡ **         | `python orchestrator/manager.py --mode inference --prompt-file prompt.txt` |
| **ì²´í¬í¬ì¸íŠ¸ë§Œ ê°•ì œ sync** | `python orchestrator/manager.py --mode sync`                               |

---

<a name="tips"></a>

## 7. ê¸°íƒ€ íŒ

* **GPU** ë‹¨ë§ì€ PyTorch + CUDA ì„¤ì¹˜ í›„ `distributed.backend` ì„ `nccl` ë¡œ.
* í•™ìŠµ ë¡œê·¸Â·ê·¸ë˜í”„ë¥¼ ë³´ê³  ì‹¶ìœ¼ë©´ `DistributedTrainer`ì— **TensorBoard** ì½”ë“œ(ë„¤ ì¤„) ë¼ì›Œ ë„£ìœ¼ë©´ ë¨.
* ë°ì´í„°ì…‹ í¬ê¸°ê°€ ìˆ˜ GiB ì´ìƒì´ë©´ `TextDataset` ì„ **ë©”ëª¨ë¦¬-ë§¤í•‘(mmap)** ë°©ì‹ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê²ƒì„ ì¶”ì²œ.  
